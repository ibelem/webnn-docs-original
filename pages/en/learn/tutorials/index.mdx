
import { Cards } from 'nextra/components'
import Image from 'next/image'
import TransformersJs from '../../../../src/components/icons/transformersjs.jsx'
import OnnxRuntime from '../../../../src/components/icons/onnxruntime.jsx'
import LiteRt from '../../../../src/components/icons/litert.jsx'
import WebNn from '../../../../src/components/icons/webnn.jsx'
import ArchitectureDiagram from '../../../../src/components/architecture.jsx'

# JavaScript ML Frameworks vs Native JavaScript API 

WebNN can be used either through supported JavaScript machine learning frameworks or directly via its native API. Choose the approach that best suits your needs.

<ArchitectureDiagram />

# ML Frameworks

WebNN API is integrating into major JavaScript machine learning frameworks like ONNX Runtime Web, Transformers.js, and LiteRT. This enables web developers to build AI applications using these high-level frameworks with less codes while leveraging WebNN's efficient, low-level neural network operations.

<Cards className="quick-start-card">
  <Cards.Card
    icon={<TransformersJs />}
    title="Transformers.js"
    href="./tutorials/transformers-js/transformers-js"
  />
  <Cards.Card
    icon={<OnnxRuntime />}
    title="ONNX Runtime"
    href="./tutorials/onnx-runtime/onnx-runtime"
  />
  <Cards.Card
    icon={<LiteRt />}
    title="Lite RT"
    href="./tutorials/lite-rt/lite-rt"
  />
</Cards>

# Native WebNN API

Use the WebNN API directly to create custom computational graphs and neural network models with greater flexibility in your AI applications.

<Cards className="quick-start-card">
  <Cards.Card
    icon={<WebNn />}
    title="Native WebNN"
    href="./tutorials/webnn/webnn"
  />
</Cards>
 