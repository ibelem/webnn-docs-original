
##  Why not define a model format that covers both topology and weights?

The WebNN API does not directly support model formats, as format handling is intentionally delegated to frameworks and applications. This design decision maintains flexibility while allowing frameworks to implement their own model loading approaches.

## Are some models restricted to specific backend or hardware?

Find operations and hardware support details of [LiteRT](../api-reference/browser-compatibility/litert), [DirectML](../api-reference/browser-compatibility/directml) and [Core ML](../api-reference/browser-compatibility/coreml) backends.

## How to maximize the optimization of the model for better inference in WebNN?